{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25cf75f8",
   "metadata": {},
   "source": [
    "## Set up environments\n",
    "\n",
    "- docker run --gpus '\"device=0\"' -it --rm -p 8887:8887 -v $(pwd):/hands_on nvcr.io/nvidia/pytorch:22.03-py3\n",
    "- cd /hands_on\n",
    "- jupyter notebook --ip 0.0.0.0 --port 8887"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052e397",
   "metadata": {},
   "source": [
    "## Make Torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c9dcd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "model = models.wide_resnet101_2(pretrained=True).eval().cuda()\n",
    "script_model = torch.jit.script(model)\n",
    "script_model.save('model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdadac8",
   "metadata": {},
   "source": [
    "TorchScript Trace vs Script\n",
    "\n",
    "1. torch.jit.trace\n",
    "-> Provide example inputs. The tracer runs the function, recording the tensor operations performed.\n",
    " (*Warning: Control-flow and data structures are ignored)\n",
    "\n",
    "2. torch.jit.script\n",
    "-> Translate model directly to TorchScript. Control-flow is preserved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7082257",
   "metadata": {},
   "source": [
    "## Make ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb537da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"actual_input_1\"]\n",
    "output_names = [\"output_1\"]\n",
    "torch.onnx.export(model, torch.randn(1, 3, 224, 224).cuda(), 'model.onnx',\n",
    "                  input_names=input_names, output_names=output_names,\n",
    "                  dynamic_axes={'actual_input_1':{0:'batch_size'}, 'output_1': {0:'batch_size'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f685afa",
   "metadata": {},
   "source": [
    "## ONNX Image\n",
    "\n",
    "https://netron.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08d7b2",
   "metadata": {},
   "source": [
    "![title](src/onnx.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d39bf",
   "metadata": {},
   "source": [
    "## Build TensorRT (ONNX -> TRT)\n",
    "\n",
    "trtexec: https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#trtexec-serialized-timing-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820d2624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8203] # trtexec --onnx=model.onnx --explicitBatch --optShapes=actual_input_1:16x3x224x224 --maxShapes=actual_input_1:32x3x224x224 --minShapes=actual_input_1:1x3x224x224 --best --saveEngine=model.plan\n",
      "[04/19/2022-05:44:24] [W] --explicitBatch flag has been deprecated and has no effect!\n",
      "[04/19/2022-05:44:24] [W] Explicit batch dim is automatically enabled if input model is ONNX or if dynamic shapes are provided when the engine is built.\n",
      "[04/19/2022-05:44:24] [I] === Model Options ===\n",
      "[04/19/2022-05:44:24] [I] Format: ONNX\n",
      "[04/19/2022-05:44:24] [I] Model: model.onnx\n",
      "[04/19/2022-05:44:24] [I] Output:\n",
      "[04/19/2022-05:44:24] [I] === Build Options ===\n",
      "[04/19/2022-05:44:24] [I] Max batch: explicit batch\n",
      "[04/19/2022-05:44:24] [I] Workspace: 16 MiB\n",
      "[04/19/2022-05:44:24] [I] minTiming: 1\n",
      "[04/19/2022-05:44:24] [I] avgTiming: 8\n",
      "[04/19/2022-05:44:24] [I] Precision: FP32+FP16+INT8\n",
      "[04/19/2022-05:44:24] [I] Calibration: Dynamic\n",
      "[04/19/2022-05:44:24] [I] Refit: Disabled\n",
      "[04/19/2022-05:44:24] [I] Sparsity: Disabled\n",
      "[04/19/2022-05:44:24] [I] Safe mode: Disabled\n",
      "[04/19/2022-05:44:24] [I] DirectIO mode: Disabled\n",
      "[04/19/2022-05:44:24] [I] Restricted mode: Disabled\n",
      "[04/19/2022-05:44:24] [I] Save engine: model.plan\n",
      "[04/19/2022-05:44:24] [I] Load engine: \n",
      "[04/19/2022-05:44:24] [I] Profiling verbosity: 0\n",
      "[04/19/2022-05:44:24] [I] Tactic sources: Using default tactic sources\n",
      "[04/19/2022-05:44:24] [I] timingCacheMode: local\n",
      "[04/19/2022-05:44:24] [I] timingCacheFile: \n",
      "[04/19/2022-05:44:24] [I] Input(s)s format: fp32:CHW\n",
      "[04/19/2022-05:44:24] [I] Output(s)s format: fp32:CHW\n",
      "[04/19/2022-05:44:24] [I] Input build shape: actual_input_1=1x3x224x224+16x3x224x224+32x3x224x224\n",
      "[04/19/2022-05:44:24] [I] Input calibration shapes: model\n",
      "[04/19/2022-05:44:24] [I] === System Options ===\n",
      "[04/19/2022-05:44:24] [I] Device: 0\n",
      "[04/19/2022-05:44:24] [I] DLACore: \n",
      "[04/19/2022-05:44:24] [I] Plugins:\n",
      "[04/19/2022-05:44:24] [I] === Inference Options ===\n",
      "[04/19/2022-05:44:24] [I] Batch: Explicit\n",
      "[04/19/2022-05:44:24] [I] Input inference shape: actual_input_1=16x3x224x224\n",
      "[04/19/2022-05:44:24] [I] Iterations: 10\n",
      "[04/19/2022-05:44:24] [I] Duration: 3s (+ 200ms warm up)\n",
      "[04/19/2022-05:44:24] [I] Sleep time: 0ms\n",
      "[04/19/2022-05:44:24] [I] Idle time: 0ms\n",
      "[04/19/2022-05:44:24] [I] Streams: 1\n",
      "[04/19/2022-05:44:24] [I] ExposeDMA: Disabled\n",
      "[04/19/2022-05:44:24] [I] Data transfers: Enabled\n",
      "[04/19/2022-05:44:24] [I] Spin-wait: Disabled\n",
      "[04/19/2022-05:44:24] [I] Multithreading: Disabled\n",
      "[04/19/2022-05:44:24] [I] CUDA Graph: Disabled\n",
      "[04/19/2022-05:44:24] [I] Separate profiling: Disabled\n",
      "[04/19/2022-05:44:24] [I] Time Deserialize: Disabled\n",
      "[04/19/2022-05:44:24] [I] Time Refit: Disabled\n",
      "[04/19/2022-05:44:24] [I] Skip inference: Disabled\n",
      "[04/19/2022-05:44:24] [I] Inputs:\n",
      "[04/19/2022-05:44:24] [I] === Reporting Options ===\n",
      "[04/19/2022-05:44:24] [I] Verbose: Disabled\n",
      "[04/19/2022-05:44:24] [I] Averages: 10 inferences\n",
      "[04/19/2022-05:44:24] [I] Percentile: 99\n",
      "[04/19/2022-05:44:24] [I] Dump refittable layers:Disabled\n",
      "[04/19/2022-05:44:24] [I] Dump output: Disabled\n",
      "[04/19/2022-05:44:24] [I] Profile: Disabled\n",
      "[04/19/2022-05:44:24] [I] Export timing to JSON file: \n",
      "[04/19/2022-05:44:24] [I] Export output to JSON file: \n",
      "[04/19/2022-05:44:24] [I] Export profile to JSON file: \n",
      "[04/19/2022-05:44:24] [I] \n",
      "[04/19/2022-05:44:24] [I] === Device Information ===\n",
      "[04/19/2022-05:44:24] [I] Selected Device: Tesla V100-DGXS-16GB\n",
      "[04/19/2022-05:44:24] [I] Compute Capability: 7.0\n",
      "[04/19/2022-05:44:24] [I] SMs: 80\n",
      "[04/19/2022-05:44:24] [I] Compute Clock Rate: 1.53 GHz\n",
      "[04/19/2022-05:44:24] [I] Device Global Memory: 16158 MiB\n",
      "[04/19/2022-05:44:24] [I] Shared Memory per SM: 96 KiB\n",
      "[04/19/2022-05:44:24] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[04/19/2022-05:44:24] [I] Memory Clock Rate: 0.877 GHz\n",
      "[04/19/2022-05:44:24] [I] \n",
      "[04/19/2022-05:44:24] [I] TensorRT version: 8.2.3\n",
      "[04/19/2022-05:44:24] [I] [TRT] [MemUsageChange] Init CUDA: CPU +261, GPU +0, now: CPU 273, GPU 3076 (MiB)\n",
      "[04/19/2022-05:44:25] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 273 MiB, GPU 3076 MiB\n",
      "[04/19/2022-05:44:25] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 384 MiB, GPU 3100 MiB\n",
      "[04/19/2022-05:44:25] [I] Start parsing network model\n",
      "[04/19/2022-05:44:25] [I] [TRT] ----------------------------------------------------------------\n",
      "[04/19/2022-05:44:25] [I] [TRT] Input filename:   model.onnx\n",
      "[04/19/2022-05:44:25] [I] [TRT] ONNX IR version:  0.0.4\n",
      "[04/19/2022-05:44:25] [I] [TRT] Opset version:    9\n",
      "[04/19/2022-05:44:25] [I] [TRT] Producer name:    pytorch\n",
      "[04/19/2022-05:44:25] [I] [TRT] Producer version: 1.12.0\n",
      "[04/19/2022-05:44:25] [I] [TRT] Domain:           \n",
      "[04/19/2022-05:44:25] [I] [TRT] Model version:    0\n",
      "[04/19/2022-05:44:25] [I] [TRT] Doc string:       \n",
      "[04/19/2022-05:44:25] [I] [TRT] ----------------------------------------------------------------\n",
      "[04/19/2022-05:44:26] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[04/19/2022-05:44:26] [I] Finish parsing network model\n",
      "[04/19/2022-05:44:26] [W] [TRT] Calibrator is not being used. Users must provide dynamic range for all tensors that are not Int32 or Bool.\n",
      "[04/19/2022-05:44:28] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +388, GPU +178, now: CPU 1272, GPU 3284 (MiB)\n",
      "[04/19/2022-05:44:29] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +117, GPU +54, now: CPU 1389, GPU 3338 (MiB)\n",
      "[04/19/2022-05:44:29] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[04/19/2022-05:44:37] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[04/19/2022-05:45:45] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[04/19/2022-05:45:46] [I] [TRT] Total Host Persistent Memory: 248096\n",
      "[04/19/2022-05:45:46] [I] [TRT] Total Device Persistent Memory: 249824256\n",
      "[04/19/2022-05:45:46] [I] [TRT] Total Scratch Memory: 704000\n",
      "[04/19/2022-05:45:46] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 252 MiB, GPU 264 MiB\n",
      "[04/19/2022-05:45:46] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 8.03045ms to assign 4 blocks to 111 nodes requiring 128450561 bytes.\n",
      "[04/19/2022-05:45:46] [I] [TRT] Total Activation Memory: 128450561\n",
      "[04/19/2022-05:45:46] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2086, GPU 3782 (MiB)\n",
      "[04/19/2022-05:45:46] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2087, GPU 3792 (MiB)\n",
      "[04/19/2022-05:45:47] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +242, GPU +243, now: CPU 242, GPU 243 (MiB)\n",
      "[04/19/2022-05:45:47] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2086, GPU 3514 (MiB)\n",
      "[04/19/2022-05:45:47] [I] [TRT] Loaded engine size: 244 MiB\n",
      "[04/19/2022-05:45:47] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2088, GPU 3768 (MiB)\n",
      "[04/19/2022-05:45:47] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2088, GPU 3776 (MiB)\n",
      "[04/19/2022-05:45:47] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +242, now: CPU 0, GPU 242 (MiB)\n",
      "[04/19/2022-05:45:47] [I] Engine built in 83.7212 sec.\n",
      "[04/19/2022-05:45:47] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 1249, GPU 3760 (MiB)\n",
      "[04/19/2022-05:45:47] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1249, GPU 3768 (MiB)\n",
      "[04/19/2022-05:45:47] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +360, now: CPU 0, GPU 602 (MiB)\n",
      "[04/19/2022-05:45:47] [I] Using random values for input actual_input_1\n",
      "[04/19/2022-05:45:47] [I] Created input binding for actual_input_1 with dimensions 16x3x224x224\n",
      "[04/19/2022-05:45:47] [I] Using random values for output output_1\n",
      "[04/19/2022-05:45:47] [I] Created output binding for output_1 with dimensions 16x1000\n",
      "[04/19/2022-05:45:47] [I] Starting inference\n",
      "[04/19/2022-05:45:51] [I] Warmup completed 17 queries over 200 ms\n",
      "[04/19/2022-05:45:51] [I] Timing trace has 255 queries over 3.03124 s\n",
      "[04/19/2022-05:45:51] [I] \n",
      "[04/19/2022-05:45:51] [I] === Trace details ===\n",
      "[04/19/2022-05:45:51] [I] Trace averages of 10 runs:\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8669 ms - Host latency: 12.6859 ms (end to end 23.6377 ms, enqueue 0.936607 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8622 ms - Host latency: 12.6978 ms (end to end 23.6239 ms, enqueue 0.928445 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8468 ms - Host latency: 12.6861 ms (end to end 23.5952 ms, enqueue 0.917252 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8481 ms - Host latency: 12.6917 ms (end to end 23.6044 ms, enqueue 0.941895 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8488 ms - Host latency: 12.6926 ms (end to end 23.5986 ms, enqueue 0.939117 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8734 ms - Host latency: 12.7186 ms (end to end 23.3215 ms, enqueue 0.936243 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8592 ms - Host latency: 12.6977 ms (end to end 23.6324 ms, enqueue 0.899792 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8265 ms - Host latency: 12.6644 ms (end to end 23.5684 ms, enqueue 0.897095 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8327 ms - Host latency: 12.6779 ms (end to end 23.5588 ms, enqueue 0.939441 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8333 ms - Host latency: 12.6759 ms (end to end 23.5709 ms, enqueue 0.945056 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8364 ms - Host latency: 12.6818 ms (end to end 23.574 ms, enqueue 0.95752 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8296 ms - Host latency: 12.6746 ms (end to end 23.563 ms, enqueue 0.943384 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8265 ms - Host latency: 12.6706 ms (end to end 23.5545 ms, enqueue 0.959302 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8365 ms - Host latency: 12.6784 ms (end to end 23.5786 ms, enqueue 0.931311 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.831 ms - Host latency: 12.6738 ms (end to end 23.5649 ms, enqueue 0.934937 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8222 ms - Host latency: 12.6651 ms (end to end 23.5501 ms, enqueue 0.935388 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.825 ms - Host latency: 12.6677 ms (end to end 23.558 ms, enqueue 0.930689 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8262 ms - Host latency: 12.6718 ms (end to end 23.5582 ms, enqueue 0.941016 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8348 ms - Host latency: 12.679 ms (end to end 23.5723 ms, enqueue 0.934521 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8321 ms - Host latency: 12.6757 ms (end to end 23.5672 ms, enqueue 0.93396 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8295 ms - Host latency: 12.675 ms (end to end 23.5652 ms, enqueue 0.937964 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8311 ms - Host latency: 12.6773 ms (end to end 23.5581 ms, enqueue 0.944971 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8317 ms - Host latency: 12.6755 ms (end to end 23.565 ms, enqueue 0.944873 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8271 ms - Host latency: 12.6703 ms (end to end 23.564 ms, enqueue 0.934082 ms)\n",
      "[04/19/2022-05:45:51] [I] Average on 10 runs - GPU latency: 11.8267 ms - Host latency: 12.6691 ms (end to end 23.5532 ms, enqueue 0.936963 ms)\n",
      "[04/19/2022-05:45:51] [I] \n",
      "[04/19/2022-05:45:51] [I] === Performance summary ===\n",
      "[04/19/2022-05:45:51] [I] Throughput: 84.1241 qps\n",
      "[04/19/2022-05:45:51] [I] Latency: min = 12.6355 ms, max = 12.7579 ms, mean = 12.6797 ms, median = 12.6766 ms, percentile(99%) = 12.7503 ms\n",
      "[04/19/2022-05:45:51] [I] End-to-End Host Latency: min = 20.355 ms, max = 23.7406 ms, mean = 23.5664 ms, median = 23.5729 ms, percentile(99%) = 23.7056 ms\n",
      "[04/19/2022-05:45:51] [I] Enqueue Time: min = 0.862427 ms, max = 1.06305 ms, mean = 0.935203 ms, median = 0.935181 ms, percentile(99%) = 1.01648 ms\n",
      "[04/19/2022-05:45:51] [I] H2D Latency: min = 0.787399 ms, max = 0.853027 ms, mean = 0.830676 ms, median = 0.831177 ms, percentile(99%) = 0.850708 ms\n",
      "[04/19/2022-05:45:51] [I] GPU Compute Time: min = 11.7976 ms, max = 11.9189 ms, mean = 11.8377 ms, median = 11.8333 ms, percentile(99%) = 11.9072 ms\n",
      "[04/19/2022-05:45:51] [I] D2H Latency: min = 0.00952148 ms, max = 0.0241699 ms, mean = 0.0113622 ms, median = 0.0111084 ms, percentile(99%) = 0.0219727 ms\n",
      "[04/19/2022-05:45:51] [I] Total Host Walltime: 3.03124 s\n",
      "[04/19/2022-05:45:51] [I] Total GPU Compute Time: 3.0186 s\n",
      "[04/19/2022-05:45:51] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[04/19/2022-05:45:51] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8203] # trtexec --onnx=model.onnx --explicitBatch --optShapes=actual_input_1:16x3x224x224 --maxShapes=actual_input_1:32x3x224x224 --minShapes=actual_input_1:1x3x224x224 --best --saveEngine=model.plan\n"
     ]
    }
   ],
   "source": [
    "!trtexec \\\n",
    "  --onnx=model.onnx \\\n",
    "  --explicitBatch \\\n",
    "  --optShapes=actual_input_1:16x3x224x224 \\\n",
    "  --maxShapes=actual_input_1:32x3x224x224 \\\n",
    "  --minShapes=actual_input_1:1x3x224x224 \\\n",
    "  --best \\\n",
    "  --saveEngine=model.plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80715e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8203] # trtexec --loadEngine=model.plan --dumpOutput\n",
      "[04/18/2022-21:49:00] [I] === Model Options ===\n",
      "[04/18/2022-21:49:00] [I] Format: *\n",
      "[04/18/2022-21:49:00] [I] Model: \n",
      "[04/18/2022-21:49:00] [I] Output:\n",
      "[04/18/2022-21:49:00] [I] === Build Options ===\n",
      "[04/18/2022-21:49:00] [I] Max batch: 1\n",
      "[04/18/2022-21:49:00] [I] Workspace: 16 MiB\n",
      "[04/18/2022-21:49:00] [I] minTiming: 1\n",
      "[04/18/2022-21:49:00] [I] avgTiming: 8\n",
      "[04/18/2022-21:49:00] [I] Precision: FP32\n",
      "[04/18/2022-21:49:00] [I] Calibration: \n",
      "[04/18/2022-21:49:00] [I] Refit: Disabled\n",
      "[04/18/2022-21:49:00] [I] Sparsity: Disabled\n",
      "[04/18/2022-21:49:00] [I] Safe mode: Disabled\n",
      "[04/18/2022-21:49:00] [I] DirectIO mode: Disabled\n",
      "[04/18/2022-21:49:00] [I] Restricted mode: Disabled\n",
      "[04/18/2022-21:49:00] [I] Save engine: \n",
      "[04/18/2022-21:49:00] [I] Load engine: model.plan\n",
      "[04/18/2022-21:49:00] [I] Profiling verbosity: 0\n",
      "[04/18/2022-21:49:00] [I] Tactic sources: Using default tactic sources\n",
      "[04/18/2022-21:49:00] [I] timingCacheMode: local\n",
      "[04/18/2022-21:49:00] [I] timingCacheFile: \n",
      "[04/18/2022-21:49:00] [I] Input(s)s format: fp32:CHW\n",
      "[04/18/2022-21:49:00] [I] Output(s)s format: fp32:CHW\n",
      "[04/18/2022-21:49:00] [I] Input build shapes: model\n",
      "[04/18/2022-21:49:00] [I] Input calibration shapes: model\n",
      "[04/18/2022-21:49:00] [I] === System Options ===\n",
      "[04/18/2022-21:49:00] [I] Device: 0\n",
      "[04/18/2022-21:49:00] [I] DLACore: \n",
      "[04/18/2022-21:49:00] [I] Plugins:\n",
      "[04/18/2022-21:49:00] [I] === Inference Options ===\n",
      "[04/18/2022-21:49:00] [I] Batch: 1\n",
      "[04/18/2022-21:49:00] [I] Input inference shapes: model\n",
      "[04/18/2022-21:49:00] [I] Iterations: 10\n",
      "[04/18/2022-21:49:00] [I] Duration: 3s (+ 200ms warm up)\n",
      "[04/18/2022-21:49:00] [I] Sleep time: 0ms\n",
      "[04/18/2022-21:49:00] [I] Idle time: 0ms\n",
      "[04/18/2022-21:49:00] [I] Streams: 1\n",
      "[04/18/2022-21:49:00] [I] ExposeDMA: Disabled\n",
      "[04/18/2022-21:49:00] [I] Data transfers: Enabled\n",
      "[04/18/2022-21:49:00] [I] Spin-wait: Disabled\n",
      "[04/18/2022-21:49:00] [I] Multithreading: Disabled\n",
      "[04/18/2022-21:49:00] [I] CUDA Graph: Disabled\n",
      "[04/18/2022-21:49:00] [I] Separate profiling: Disabled\n",
      "[04/18/2022-21:49:00] [I] Time Deserialize: Disabled\n",
      "[04/18/2022-21:49:00] [I] Time Refit: Disabled\n",
      "[04/18/2022-21:49:00] [I] Skip inference: Disabled\n",
      "[04/18/2022-21:49:00] [I] Inputs:\n",
      "[04/18/2022-21:49:00] [I] === Reporting Options ===\n",
      "[04/18/2022-21:49:00] [I] Verbose: Disabled\n",
      "[04/18/2022-21:49:00] [I] Averages: 10 inferences\n",
      "[04/18/2022-21:49:00] [I] Percentile: 99\n",
      "[04/18/2022-21:49:00] [I] Dump refittable layers:Disabled\n",
      "[04/18/2022-21:49:00] [I] Dump output: Enabled\n",
      "[04/18/2022-21:49:00] [I] Profile: Disabled\n",
      "[04/18/2022-21:49:00] [I] Export timing to JSON file: \n",
      "[04/18/2022-21:49:00] [I] Export output to JSON file: \n",
      "[04/18/2022-21:49:00] [I] Export profile to JSON file: \n",
      "[04/18/2022-21:49:00] [I] \n",
      "[04/18/2022-21:49:00] [I] === Device Information ===\n",
      "[04/18/2022-21:49:00] [I] Selected Device: Tesla V100-DGXS-16GB\n",
      "[04/18/2022-21:49:00] [I] Compute Capability: 7.0\n",
      "[04/18/2022-21:49:00] [I] SMs: 80\n",
      "[04/18/2022-21:49:00] [I] Compute Clock Rate: 1.53 GHz\n",
      "[04/18/2022-21:49:00] [I] Device Global Memory: 16158 MiB\n",
      "[04/18/2022-21:49:00] [I] Shared Memory per SM: 96 KiB\n",
      "[04/18/2022-21:49:00] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[04/18/2022-21:49:00] [I] Memory Clock Rate: 0.877 GHz\n",
      "[04/18/2022-21:49:00] [I] \n",
      "[04/18/2022-21:49:00] [I] TensorRT version: 8.2.3\n",
      "[04/18/2022-21:49:01] [I] [TRT] [MemUsageChange] Init CUDA: CPU +261, GPU +0, now: CPU 517, GPU 4318 (MiB)\n",
      "[04/18/2022-21:49:01] [I] [TRT] Loaded engine size: 244 MiB\n",
      "[04/18/2022-21:49:01] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +387, GPU +178, now: CPU 908, GPU 4742 (MiB)\n",
      "[04/18/2022-21:49:01] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +117, GPU +54, now: CPU 1025, GPU 4796 (MiB)\n",
      "[04/18/2022-21:49:01] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +242, now: CPU 0, GPU 242 (MiB)\n",
      "[04/18/2022-21:49:01] [I] Engine loaded in 1.69154 sec.\n",
      "[04/18/2022-21:49:01] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 781, GPU 4788 (MiB)\n",
      "[04/18/2022-21:49:01] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 781, GPU 4796 (MiB)\n",
      "[04/18/2022-21:49:01] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +360, now: CPU 0, GPU 602 (MiB)\n",
      "[04/18/2022-21:49:01] [W] Dynamic dimensions required for input: actual_input_1, but no shapes were provided. Automatically overriding shape to: 1x3x224x224\n",
      "[04/18/2022-21:49:01] [I] Using random values for input actual_input_1\n",
      "[04/18/2022-21:49:01] [I] Created input binding for actual_input_1 with dimensions 1x3x224x224\n",
      "[04/18/2022-21:49:01] [I] Using random values for output output_1\n",
      "[04/18/2022-21:49:01] [I] Created output binding for output_1 with dimensions 1x1000\n",
      "[04/18/2022-21:49:01] [I] Starting inference\n",
      "[04/18/2022-21:49:05] [I] Warmup completed 38 queries over 200 ms\n",
      "[04/18/2022-21:49:05] [I] Timing trace has 570 queries over 3.01349 s\n",
      "[04/18/2022-21:49:05] [I] \n",
      "[04/18/2022-21:49:05] [I] === Trace details ===\n",
      "[04/18/2022-21:49:05] [I] Trace averages of 10 runs:\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27434 ms - Host latency: 5.34227 ms (end to end 10.4476 ms, enqueue 0.946884 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27519 ms - Host latency: 5.34305 ms (end to end 10.4453 ms, enqueue 0.967853 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27398 ms - Host latency: 5.34254 ms (end to end 10.4442 ms, enqueue 0.959567 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27305 ms - Host latency: 5.34151 ms (end to end 10.4426 ms, enqueue 0.956946 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27435 ms - Host latency: 5.34533 ms (end to end 10.4468 ms, enqueue 0.95325 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27422 ms - Host latency: 5.34163 ms (end to end 10.4465 ms, enqueue 0.955045 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.2739 ms - Host latency: 5.34233 ms (end to end 10.4471 ms, enqueue 0.952496 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27352 ms - Host latency: 5.34208 ms (end to end 10.4435 ms, enqueue 0.951135 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27414 ms - Host latency: 5.34191 ms (end to end 10.4454 ms, enqueue 0.954376 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.2758 ms - Host latency: 5.34543 ms (end to end 10.4468 ms, enqueue 0.951239 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27604 ms - Host latency: 5.34514 ms (end to end 10.4471 ms, enqueue 0.954755 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.2738 ms - Host latency: 5.34145 ms (end to end 10.4526 ms, enqueue 0.90517 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.2744 ms - Host latency: 5.34278 ms (end to end 10.4578 ms, enqueue 0.869989 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27396 ms - Host latency: 5.34142 ms (end to end 10.4523 ms, enqueue 0.862305 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27416 ms - Host latency: 5.34211 ms (end to end 10.4582 ms, enqueue 0.864972 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27553 ms - Host latency: 5.34506 ms (end to end 10.4559 ms, enqueue 0.893225 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27646 ms - Host latency: 5.34674 ms (end to end 10.4538 ms, enqueue 0.926062 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27471 ms - Host latency: 5.34404 ms (end to end 10.4472 ms, enqueue 0.951416 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27479 ms - Host latency: 5.34442 ms (end to end 10.447 ms, enqueue 0.953931 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27345 ms - Host latency: 5.34366 ms (end to end 10.4461 ms, enqueue 0.949585 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27554 ms - Host latency: 5.34495 ms (end to end 10.4498 ms, enqueue 0.954993 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27394 ms - Host latency: 5.34403 ms (end to end 10.4448 ms, enqueue 0.948584 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27351 ms - Host latency: 5.34283 ms (end to end 10.4431 ms, enqueue 0.950891 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27461 ms - Host latency: 5.34469 ms (end to end 10.4453 ms, enqueue 0.951025 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27394 ms - Host latency: 5.34396 ms (end to end 10.4447 ms, enqueue 0.950305 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27378 ms - Host latency: 5.34323 ms (end to end 10.4464 ms, enqueue 0.954529 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27476 ms - Host latency: 5.34468 ms (end to end 10.4448 ms, enqueue 0.951428 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27445 ms - Host latency: 5.34409 ms (end to end 10.438 ms, enqueue 0.950232 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27686 ms - Host latency: 5.3488 ms (end to end 10.4485 ms, enqueue 0.94624 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27389 ms - Host latency: 5.34381 ms (end to end 10.4431 ms, enqueue 0.944812 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27435 ms - Host latency: 5.34363 ms (end to end 10.4528 ms, enqueue 0.900085 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27516 ms - Host latency: 5.34244 ms (end to end 10.4596 ms, enqueue 0.87666 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27382 ms - Host latency: 5.34124 ms (end to end 10.4606 ms, enqueue 0.861914 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27296 ms - Host latency: 5.34041 ms (end to end 10.4565 ms, enqueue 0.868506 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.2751 ms - Host latency: 5.34285 ms (end to end 10.4573 ms, enqueue 0.89082 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27241 ms - Host latency: 5.34127 ms (end to end 10.4455 ms, enqueue 0.927405 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27485 ms - Host latency: 5.34473 ms (end to end 10.4486 ms, enqueue 0.951758 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27395 ms - Host latency: 5.3436 ms (end to end 10.4435 ms, enqueue 0.951758 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27461 ms - Host latency: 5.34402 ms (end to end 10.4479 ms, enqueue 0.95647 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27336 ms - Host latency: 5.34241 ms (end to end 10.4452 ms, enqueue 0.949097 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27488 ms - Host latency: 5.34495 ms (end to end 10.4452 ms, enqueue 0.951611 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27417 ms - Host latency: 5.34368 ms (end to end 10.4396 ms, enqueue 0.951001 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27432 ms - Host latency: 5.34353 ms (end to end 10.4421 ms, enqueue 0.948242 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.2751 ms - Host latency: 5.34563 ms (end to end 10.4467 ms, enqueue 1.06487 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27373 ms - Host latency: 5.34075 ms (end to end 10.4566 ms, enqueue 0.617651 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27341 ms - Host latency: 5.34053 ms (end to end 10.4563 ms, enqueue 0.612573 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27478 ms - Host latency: 5.34351 ms (end to end 10.4583 ms, enqueue 0.655029 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27322 ms - Host latency: 5.34277 ms (end to end 10.4414 ms, enqueue 0.923584 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27351 ms - Host latency: 5.34275 ms (end to end 10.4428 ms, enqueue 0.944385 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27349 ms - Host latency: 5.34207 ms (end to end 10.4491 ms, enqueue 0.857861 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27412 ms - Host latency: 5.34241 ms (end to end 10.4518 ms, enqueue 0.798462 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27541 ms - Host latency: 5.34448 ms (end to end 10.4517 ms, enqueue 0.801294 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27476 ms - Host latency: 5.34375 ms (end to end 10.4485 ms, enqueue 0.798047 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.2739 ms - Host latency: 5.34277 ms (end to end 10.449 ms, enqueue 0.796094 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27417 ms - Host latency: 5.3428 ms (end to end 10.4537 ms, enqueue 0.799316 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27327 ms - Host latency: 5.34199 ms (end to end 10.4444 ms, enqueue 0.79751 ms)\n",
      "[04/18/2022-21:49:05] [I] Average on 10 runs - GPU latency: 5.27271 ms - Host latency: 5.34158 ms (end to end 10.4431 ms, enqueue 0.802075 ms)\n",
      "[04/18/2022-21:49:05] [I] \n",
      "[04/18/2022-21:49:05] [I] === Performance summary ===\n",
      "[04/18/2022-21:49:05] [I] Throughput: 189.149 qps\n",
      "[04/18/2022-21:49:05] [I] Latency: min = 5.33423 ms, max = 5.36743 ms, mean = 5.34327 ms, median = 5.34302 ms, percentile(99%) = 5.354 ms\n",
      "[04/18/2022-21:49:05] [I] End-to-End Host Latency: min = 10.3965 ms, max = 10.4714 ms, mean = 10.4484 ms, median = 10.4495 ms, percentile(99%) = 10.468 ms\n",
      "[04/18/2022-21:49:05] [I] Enqueue Time: min = 0.593994 ms, max = 1.51489 ms, mean = 0.902409 ms, median = 0.945389 ms, percentile(99%) = 1.00223 ms\n",
      "[04/18/2022-21:49:05] [I] H2D Latency: min = 0.0581055 ms, max = 0.0853271 ms, mean = 0.0614119 ms, median = 0.0612793 ms, percentile(99%) = 0.0700684 ms\n",
      "[04/18/2022-21:49:05] [I] GPU Compute Time: min = 5.26636 ms, max = 5.28516 ms, mean = 5.27429 ms, median = 5.27417 ms, percentile(99%) = 5.28198 ms\n",
      "[04/18/2022-21:49:05] [I] D2H Latency: min = 0.00512695 ms, max = 0.010498 ms, mean = 0.00756964 ms, median = 0.00769043 ms, percentile(99%) = 0.0098877 ms\n",
      "[04/18/2022-21:49:05] [I] Total Host Walltime: 3.01349 s\n",
      "[04/18/2022-21:49:05] [I] Total GPU Compute Time: 3.00635 s\n",
      "[04/18/2022-21:49:05] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[04/18/2022-21:49:05] [I] \n",
      "[04/18/2022-21:49:05] [I] Output Tensors:\n",
      "[04/18/2022-21:49:05] [I] output_1: (1x1000)\n",
      "[04/18/2022-21:49:05] [I] -0.329346 0.466553 1.60938 0.811523 2.17773 0.601074 2.12109 0.399414 0.427734 0.461182 -0.418701 1.06348 1.39062 0.553223 0.422119 0.27832 -0.787109 -0.00681305 1.51172 0.0402222 -0.267578 0.301758 0.995605 1.43164 0.190918 -1.3623 0.658203 1.07812 -0.398926 -0.118103 -0.634766 0.477783 -1.64941 0.831055 0.942871 -1.68945 1.15527 -0.646484 1.78809 -0.640625 1.94141 0.439453 -0.266113 -0.805176 1.28418 -0.263184 2.23438 -0.678223 0.322021 -0.789062 0.791016 -2.07031 0.260254 0.342529 0.364258 -1.16406 0.0312805 0.355469 0.70459 0.0520325 0.952148 0.0536804 -0.168579 0.0809326 -0.317383 1.58105 0.100342 0.0123978 0.0342407 1.63672 0.172363 1.64648 -0.662109 0.961426 -0.118164 2.25586 0.287598 2.58789 3.63672 2.78516 0.491211 -1.39355 -0.0804443 -0.714844 -0.059021 1.24805 -0.0881958 1.64258 -0.73584 0.0862427 -0.591309 0.0670776 0.337646 -0.118469 -0.391357 -2.62109 1.48047 -0.0905151 0.128174 1.28516 1.23047 -0.75 -0.710938 0.369629 0.341553 -1.125 -0.893066 0.0943604 -1.31348 0.772949 0.90625 4.98047 0.396484 1.5293 1.97949 -1.38379 0.523438 1.07031 0.194214 0.269043 0.874512 -0.121704 -1.33594 -1.18848 -0.01297 0.290283 2.66602 -0.371338 0.896973 0.562988 -0.580566 0.733398 0.444824 0.478027 0.851074 -0.599121 0.87793 1.40625 2.4043 0.0986938 0.382568 0.718262 1.03418 1.15039 -0.39624 1.04785 0.896973 0.293701 0.491699 1.05176 -0.505371 0.274414 -2.92383 -0.914062 -1.85059 -1.09473 -1.58398 -1.51074 -1.26367 -0.862793 -2.00586 -0.10614 0.221924 -0.588379 -0.634766 -1.02441 -0.166626 -2.13867 -0.713867 -0.732422 -1.05859 0.740234 -0.505371 -0.117004 -0.482666 -1.69727 -2.5293 -1.1084 0.983887 -1.75 0.45459 -0.851562 0.575684 -0.92627 -0.669922 -0.884766 -1.03906 -0.831055 -1.58691 -1.64062 -1.06152 -0.294189 0.0424194 1.13379 -2.51758 1.57617 -0.677734 -0.361572 -0.76416 -0.378418 -0.109497 -0.0346985 -0.195557 -0.311279 -0.0894775 -0.819336 -0.812012 -1.74707 -1.3457 -0.76709 -1.30762 -1.22656 0.0812988 -0.703613 -1.15137 0.25708 -1.06348 0.86084 -0.669434 0.0784302 -1.59863 1.56543 -1.68066 0.036438 -0.960449 -1.4707 -0.723145 0.26001 -0.54541 1.40723 -1.51465 0.537109 1.0791 -1.91797 -1.15527 -0.0714111 -0.0878906 0.0666504 0.232666 -0.612305 -0.665039 0.00793457 -0.79541 -1.90918 -2.43164 0.292236 -0.104187 -1.42969 -0.485596 -0.206299 -0.934082 0.411621 -1.13477 -0.57959 -0.341553 -2.26758 -0.13855 -2.19141 -1.25586 -1.09766 -0.470947 -0.842773 -3.06836 -0.0733643 -0.42334 0.213379 0.907715 -1.66602 -1.9541 -1.37598 -0.142456 -0.725586 0.592285 -0.272461 -2.07812 -1.9248 0.190796 -2.10352 -1.17676 -0.565918 -0.399414 0.998535 0.950195 -0.475098 1.13086 1.39551 -1.50781 -2.01953 -0.841797 -0.913086 -1.56934 -1.88672 -2.32422 -0.299561 -0.672852 0.0291595 0.0279388 -1.49414 0.364502 -1.27246 -1.16895 2.52734 1.09961 1.2832 0.401123 -0.271729 0.481445 1.05957 1.42578 0.0343628 2.06445 1.8623 1.80176 2.32812 2.30664 1.39941 1.57715 2.95703 3.69336 0.477539 -0.0293732 -1.65137 -1.0332 -1.61133 -0.963379 0.275635 -0.984863 1.4082 0.00471878 -1.24805 0.392822 0.0156555 -0.0385437 -1.33203 -0.0236359 -1.26465 -1.33398 -0.369385 -0.874023 -1.47363 -0.866211 -0.919922 -0.854492 -1.8457 -1.34863 -0.712891 -1.3252 -0.660645 -0.355713 -0.924316 -1.38867 -0.851562 -1.62891 -0.115784 -0.772949 -0.248535 -0.179199 0.244995 0.107666 0.250244 -0.753418 -0.154053 -1.05762 1.17285 -0.723145 -1.35938 -0.734863 -1.06348 -1.54785 -1.25586 0.0961914 -2.25195 -0.270264 -1.73633 -1.32129 -1.59863 -2.20312 -0.358643 -1.59277 -1.16309 -2.17578 -0.672363 0.306641 -0.611328 -3.61719 -1.51758 -1.14941 -2.79688 -1.55957 -0.410156 1.65625 1.72461 -0.0822144 -0.0898438 0.452881 1.04492 -1.55469 1.28418 0.365479 1.01758 -2.2168 -0.523926 1.08594 0.397217 -0.945312 1.50293 -2.75 -2.48633 -2.55664 0.662598 1.12793 5.73438 2.60156 1.375 1.77832 -3.72656 0.609375 0.333252 2.00195 1.83008 0.676758 -0.171997 -0.561523 -1.97754 -2.08203 0.0324402 -0.977539 -0.398682 -0.912109 0.23291 -0.532227 -1.32617 1.88281 -0.60498 -1.08496 -1.48828 0.268066 -0.505371 -0.250488 0.178833 0.289551 -0.0587158 -1.32715 4.62891 -0.095459 -1.58984 5.33594 -0.315674 0.57959 -2.08984 -2.54297 2.52344 0.820801 -2.16992 -1.03125 3.10352 -0.09375 1.62988 -0.139038 -0.946289 -1.20703 0.910645 2.76953 0.342773 3.47461 1.49805 -2.21094 -2.61133 -1.91602 1.03223 -0.393066 -0.639648 -0.730469 2.89844 2.15234 -1.99512 -3.43555 0.235962 1.42383 -1.5957 1.59766 2.34961 0.611328 -1.81934 -0.35791 0.621094 -0.674316 2.125 3.05469 2.38477 6.89844 0.337402 1.29688 -1.23828 0.130615 -1.78516 1.18848 -0.556152 -1.11328 1.77832 -0.240723 0.793457 0.0693359 0.474365 0.180298 -0.820312 2.10938 1.4209 1.4209 -2.16211 -1.07617 -1.71582 2.54688 1.17578 0.619141 1.00488 -0.714355 -0.646484 -0.570312 0.2323 -1.18555 0.429199 0.24585 0.484375 0.745117 -1.81055 -2.00391 -0.997559 -0.233521 -0.286865 0.497803 0.1604 -1.37695 3.2793 3.33203 -1.72266 -0.440674 -0.794434 0.0294495 4.70312 -0.122803 0.475586 2.65625 0.443604 0.523438 0.23938 0.0315247 -2.59766 -1.39355 5.01172 -1.75781 -1.16211 1.30664 1.37305 -0.182861 -2.10352 4.74609 -0.23645 2.17773 1.86719 -0.476074 -0.618164 -1.29297 3.42188 -2.09375 -1.2334 2.36914 0.779297 1.01465 -2.53125 0.318848 -1.08984 0.103027 -0.863281 1.87109 -2.14258 -1.16992 -0.124207 -1.63965 -0.853027 -1.17383 2.03906 -3.22266 1.08203 1.49316 0.346436 0.395264 2.05273 2.06836 0.805176 -1.7666 3.63672 -1.0752 0.71875 -0.51123 -1.34766 1.66699 2.0293 -0.753906 2.54102 2.07422 1.12793 0.0840454 -4.15234 0.216064 1.37793 0.975586 -0.353516 3.16797 -2.29883 3.28125 2.47266 -1.77734 2.54297 -0.785156 -0.270508 2.67578 -0.43457 2.41992 1.82129 1.95898 -0.318115 1.75781 2.37305 -0.647949 -1.80957 1.54492 -2.46484 0.565918 2.45312 1.23047 -0.178711 2.67383 0.455566 -1.89551 0.0311279 2.27539 -0.615234 0.349121 0.568848 0.891602 -0.21228 -0.0567932 0.983887 2.95508 -1.32031 0.98877 -0.143677 -2.44531 -0.776367 3.67969 0.44873 -0.730957 0.315674 -2.9082 3.86133 -1.85449 2 0.277344 -1.14648 -1.25488 -2.22266 0.306641 -1.61035 -0.109131 -1.71387 -0.786133 -0.000366211 -0.276123 -0.741699 -1.41309 -2.58984 -1.63574 1.5918 2.44922 -1.66016 -0.440674 3.87891 -0.598145 3.8457 -0.817871 1.11035 -0.427734 2.88477 0.686523 -0.511719 1.29297 -0.90625 0.824707 0.557617 -3.28906 -2.21484 0.785156 1.24707 -1.61816 1.90137 1.2627 -1.32422 -2.13477 0.61377 2.42578 1.08008 -1.16309 -1.14746 1.27734 -1.59863 -2.64453 0.238525 0.139771 2.44727 1.06445 -0.0888062 0.182495 0.282471 3.04102 -0.411865 0.855469 -2.66797 -0.780273 0.249756 -0.212158 3.68945 2.63086 -0.130615 -1.74707 -0.113647 0.142944 0.586426 0.345947 -2.10742 0.530273 2.38281 -0.00514984 1.69043 -2.61133 3.58398 0.830566 0.746094 0.244873 -2.0332 0.378418 4.10938 -0.00352859 -1.43652 0.889648 -0.994629 0.717285 0.25708 1.68262 2.40625 1.12305 -1.3916 2.92969 3.91016 0.92627 -0.504395 1.27344 -1.7002 -0.564453 -0.390625 1.62109 0.683594 -3.73828 3.34766 1.51953 0.123474 -1.94141 2.49023 0.43335 3.08789 0.831543 0.328857 3.9082 0.56543 1.71973 0.401367 0.494385 4.8125 -0.47998 -1.91016 -0.894043 -1.23926 1.06934 4.04688 4.30469 -0.0787964 -0.477783 1.36426 0.319092 0.560547 0.849121 0.902344 1.83789 -0.285889 1.18359 0.294922 3.31836 1.59961 0.58252 -0.0853271 -1.57812 -0.317139 -0.802734 -1.45898 0.862793 1.11914 1.24707 -0.670898 0.417725 0.859863 -1.70312 3.19922 0.782227 1.86621 -1.08984 -0.244385 1.40723 -2.89844 -0.739746 -0.721191 -2.04492 -1.82812 -1.95215 -1.24023 0.401367 -1.62988 -0.310303 1.13281 2.07227 -2.83789 -0.771484 -0.327881 -1.67676 0.936035 2.57031 -1.38867 -0.639648 0.335693 -0.0405884 -0.516602 2.4375 2.36914 0.300049 -0.735352 2.64648 3.14648 0.505859 -0.991211 0.587891 1.26855 -0.376709 0.588867 2.2793 -1.15234 0.0685425 2.56055 -1.12793 -1.01172 0.090332 0.908691 -2.46484 0.399658 -0.583496 -1.26465 -2.91992 -2.73633 -0.975098 -2.31055 2.56641 1.38379 -0.0489502 -0.360352 1.5752 -0.272461 -3.18359 -0.63916 -0.935547 0.271729 0.108643 2.05859 0.496094 -0.959473 1.68262 0.942871 -1.29297 3.37695 -0.652344 -1.04199 -2.10352 -1.16016 -2.05859 -0.812012 3.29688 2.84375 1.24902 -0.119873 -0.0520325 -0.513672 1.7832 -1.00195 -1.21777 0.0203552 1.18262 0.260986 5.84375 0.138184 1.19141 -0.0419312 1.10059 -0.465088 2.65039 3.68359 -1.69531 -0.768555 -0.98584 -2.00781 -1.13574 -0.369141 1.19824 -0.952637 -1.08496 3.00195 -0.561523 -2.37305 -1.50195 -1.12012 -1.9873 -1.83789 -0.857422 -0.18457 -1.95117 -0.818848 0.73291 -1.36719 -1.76172 -1.16113 -1.19434 -0.821777 -1.81836 -0.510742 -0.425049 -1.87988 -0.590332 -0.879883 -1.8291 -0.865234 -2.69141 -0.446777 0.808594 -0.0917969 0.499268 -0.331299 -0.0201111 -0.385498 -0.101074 -1.26855 -2.27344 -0.73291 0.263916 -0.47168 -1.23047 0.214844 -1.59277 0.34082 -0.730469 -2.18945 -0.215454 0.557617 0.0970459 -1.55957 -2.14844 1.7627 -1.50781 0.403564 0.239868 -1.59668 -1.18359 1.41309 -1.43555 -2.70898 -0.629395 -0.32959 -2.58789 0.607422 -0.90918 -0.878906 -2.36328 -0.529785 0.230225 -0.72168 -0.222168 -4.95911e-05 -0.440186 -2.56836 -1.51367 -1.83984 -1.17188 -0.494385 -0.552246 1.07031\n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8203] # trtexec --loadEngine=model.plan --dumpOutput\n"
     ]
    }
   ],
   "source": [
    "!trtexec --loadEngine=model.plan --dumpOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bc75d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8203] # trtexec --loadEngine=model.plan --dumpProfile\n",
      "[04/18/2022-21:49:09] [I] === Model Options ===\n",
      "[04/18/2022-21:49:09] [I] Format: *\n",
      "[04/18/2022-21:49:09] [I] Model: \n",
      "[04/18/2022-21:49:09] [I] Output:\n",
      "[04/18/2022-21:49:09] [I] === Build Options ===\n",
      "[04/18/2022-21:49:09] [I] Max batch: 1\n",
      "[04/18/2022-21:49:09] [I] Workspace: 16 MiB\n",
      "[04/18/2022-21:49:09] [I] minTiming: 1\n",
      "[04/18/2022-21:49:09] [I] avgTiming: 8\n",
      "[04/18/2022-21:49:09] [I] Precision: FP32\n",
      "[04/18/2022-21:49:09] [I] Calibration: \n",
      "[04/18/2022-21:49:09] [I] Refit: Disabled\n",
      "[04/18/2022-21:49:09] [I] Sparsity: Disabled\n",
      "[04/18/2022-21:49:09] [I] Safe mode: Disabled\n",
      "[04/18/2022-21:49:09] [I] DirectIO mode: Disabled\n",
      "[04/18/2022-21:49:09] [I] Restricted mode: Disabled\n",
      "[04/18/2022-21:49:09] [I] Save engine: \n",
      "[04/18/2022-21:49:09] [I] Load engine: model.plan\n",
      "[04/18/2022-21:49:09] [I] Profiling verbosity: 0\n",
      "[04/18/2022-21:49:09] [I] Tactic sources: Using default tactic sources\n",
      "[04/18/2022-21:49:09] [I] timingCacheMode: local\n",
      "[04/18/2022-21:49:09] [I] timingCacheFile: \n",
      "[04/18/2022-21:49:09] [I] Input(s)s format: fp32:CHW\n",
      "[04/18/2022-21:49:09] [I] Output(s)s format: fp32:CHW\n",
      "[04/18/2022-21:49:09] [I] Input build shapes: model\n",
      "[04/18/2022-21:49:09] [I] Input calibration shapes: model\n",
      "[04/18/2022-21:49:09] [I] === System Options ===\n",
      "[04/18/2022-21:49:09] [I] Device: 0\n",
      "[04/18/2022-21:49:09] [I] DLACore: \n",
      "[04/18/2022-21:49:09] [I] Plugins:\n",
      "[04/18/2022-21:49:09] [I] === Inference Options ===\n",
      "[04/18/2022-21:49:09] [I] Batch: 1\n",
      "[04/18/2022-21:49:09] [I] Input inference shapes: model\n",
      "[04/18/2022-21:49:09] [I] Iterations: 10\n",
      "[04/18/2022-21:49:09] [I] Duration: 3s (+ 200ms warm up)\n",
      "[04/18/2022-21:49:09] [I] Sleep time: 0ms\n",
      "[04/18/2022-21:49:09] [I] Idle time: 0ms\n",
      "[04/18/2022-21:49:09] [I] Streams: 1\n",
      "[04/18/2022-21:49:09] [I] ExposeDMA: Disabled\n",
      "[04/18/2022-21:49:09] [I] Data transfers: Enabled\n",
      "[04/18/2022-21:49:09] [I] Spin-wait: Disabled\n",
      "[04/18/2022-21:49:09] [I] Multithreading: Disabled\n",
      "[04/18/2022-21:49:09] [I] CUDA Graph: Disabled\n",
      "[04/18/2022-21:49:09] [I] Separate profiling: Disabled\n",
      "[04/18/2022-21:49:09] [I] Time Deserialize: Disabled\n",
      "[04/18/2022-21:49:09] [I] Time Refit: Disabled\n",
      "[04/18/2022-21:49:09] [I] Skip inference: Disabled\n",
      "[04/18/2022-21:49:09] [I] Inputs:\n",
      "[04/18/2022-21:49:09] [I] === Reporting Options ===\n",
      "[04/18/2022-21:49:09] [I] Verbose: Disabled\n",
      "[04/18/2022-21:49:09] [I] Averages: 10 inferences\n",
      "[04/18/2022-21:49:09] [I] Percentile: 99\n",
      "[04/18/2022-21:49:09] [I] Dump refittable layers:Disabled\n",
      "[04/18/2022-21:49:09] [I] Dump output: Disabled\n",
      "[04/18/2022-21:49:09] [I] Profile: Enabled\n",
      "[04/18/2022-21:49:09] [I] Export timing to JSON file: \n",
      "[04/18/2022-21:49:09] [I] Export output to JSON file: \n",
      "[04/18/2022-21:49:09] [I] Export profile to JSON file: \n",
      "[04/18/2022-21:49:09] [I] \n",
      "[04/18/2022-21:49:09] [I] === Device Information ===\n",
      "[04/18/2022-21:49:09] [I] Selected Device: Tesla V100-DGXS-16GB\n",
      "[04/18/2022-21:49:09] [I] Compute Capability: 7.0\n",
      "[04/18/2022-21:49:09] [I] SMs: 80\n",
      "[04/18/2022-21:49:09] [I] Compute Clock Rate: 1.53 GHz\n",
      "[04/18/2022-21:49:09] [I] Device Global Memory: 16158 MiB\n",
      "[04/18/2022-21:49:09] [I] Shared Memory per SM: 96 KiB\n",
      "[04/18/2022-21:49:09] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[04/18/2022-21:49:09] [I] Memory Clock Rate: 0.877 GHz\n",
      "[04/18/2022-21:49:09] [I] \n",
      "[04/18/2022-21:49:09] [I] TensorRT version: 8.2.3\n",
      "[04/18/2022-21:49:10] [I] [TRT] [MemUsageChange] Init CUDA: CPU +261, GPU +0, now: CPU 517, GPU 4318 (MiB)\n",
      "[04/18/2022-21:49:10] [I] [TRT] Loaded engine size: 244 MiB\n",
      "[04/18/2022-21:49:11] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +387, GPU +178, now: CPU 908, GPU 4742 (MiB)\n",
      "[04/18/2022-21:49:11] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +117, GPU +54, now: CPU 1025, GPU 4796 (MiB)\n",
      "[04/18/2022-21:49:11] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +242, now: CPU 0, GPU 242 (MiB)\n",
      "[04/18/2022-21:49:11] [I] Engine loaded in 1.68489 sec.\n",
      "[04/18/2022-21:49:11] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 781, GPU 4788 (MiB)\n",
      "[04/18/2022-21:49:11] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 781, GPU 4796 (MiB)\n",
      "[04/18/2022-21:49:11] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +360, now: CPU 0, GPU 602 (MiB)\n",
      "[04/18/2022-21:49:11] [W] Dynamic dimensions required for input: actual_input_1, but no shapes were provided. Automatically overriding shape to: 1x3x224x224\n",
      "[04/18/2022-21:49:11] [I] Using random values for input actual_input_1\n",
      "[04/18/2022-21:49:11] [I] Created input binding for actual_input_1 with dimensions 1x3x224x224\n",
      "[04/18/2022-21:49:11] [I] Using random values for output output_1\n",
      "[04/18/2022-21:49:11] [I] Created output binding for output_1 with dimensions 1x1000\n",
      "[04/18/2022-21:49:11] [I] Starting inference\n",
      "[04/18/2022-21:49:14] [W] The network timing report will not be accurate due to extra synchronizations when profiler is enabled.\n",
      "[04/18/2022-21:49:14] [W] Add --separateProfileRun to profile layer timing in a separate run.\n",
      "[04/18/2022-21:49:14] [I] Warmup completed 34 queries over 200 ms\n",
      "[04/18/2022-21:49:14] [I] Timing trace has 517 queries over 3.0117 s\n",
      "[04/18/2022-21:49:14] [I] \n",
      "[04/18/2022-21:49:14] [I] === Trace details ===\n",
      "[04/18/2022-21:49:14] [I] Trace averages of 10 runs:\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71586 ms - Host latency: 5.78045 ms (end to end 5.79198 ms, enqueue 5.76064 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72411 ms - Host latency: 5.78965 ms (end to end 5.80271 ms, enqueue 5.76884 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72309 ms - Host latency: 5.78987 ms (end to end 5.80348 ms, enqueue 5.76755 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72344 ms - Host latency: 5.79067 ms (end to end 5.80382 ms, enqueue 5.76868 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71414 ms - Host latency: 5.78089 ms (end to end 5.79186 ms, enqueue 5.75916 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71262 ms - Host latency: 5.77805 ms (end to end 5.79041 ms, enqueue 5.76004 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70705 ms - Host latency: 5.77323 ms (end to end 5.78472 ms, enqueue 5.75573 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70493 ms - Host latency: 5.77105 ms (end to end 5.78419 ms, enqueue 5.75433 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70504 ms - Host latency: 5.77017 ms (end to end 5.78482 ms, enqueue 5.75553 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70289 ms - Host latency: 5.77018 ms (end to end 5.78215 ms, enqueue 5.75125 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70514 ms - Host latency: 5.77012 ms (end to end 5.78261 ms, enqueue 5.75379 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70783 ms - Host latency: 5.77305 ms (end to end 5.78437 ms, enqueue 5.75465 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70659 ms - Host latency: 5.77143 ms (end to end 5.78435 ms, enqueue 5.75545 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70902 ms - Host latency: 5.77628 ms (end to end 5.78909 ms, enqueue 5.75844 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71511 ms - Host latency: 5.78173 ms (end to end 5.79369 ms, enqueue 5.76251 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71946 ms - Host latency: 5.78845 ms (end to end 5.80134 ms, enqueue 5.76693 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.724 ms - Host latency: 5.79296 ms (end to end 5.80725 ms, enqueue 5.77076 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72581 ms - Host latency: 5.79371 ms (end to end 5.80723 ms, enqueue 5.77061 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.73137 ms - Host latency: 5.80101 ms (end to end 5.81364 ms, enqueue 5.77698 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.73026 ms - Host latency: 5.79893 ms (end to end 5.81147 ms, enqueue 5.77498 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72368 ms - Host latency: 5.79343 ms (end to end 5.80673 ms, enqueue 5.77157 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71992 ms - Host latency: 5.7885 ms (end to end 5.80016 ms, enqueue 5.76694 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70708 ms - Host latency: 5.77434 ms (end to end 5.7858 ms, enqueue 5.75498 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70587 ms - Host latency: 5.77214 ms (end to end 5.78434 ms, enqueue 5.75548 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70461 ms - Host latency: 5.76956 ms (end to end 5.78652 ms, enqueue 5.75588 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71132 ms - Host latency: 5.7793 ms (end to end 5.79161 ms, enqueue 5.75979 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71841 ms - Host latency: 5.78566 ms (end to end 5.79847 ms, enqueue 5.76708 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72105 ms - Host latency: 5.78971 ms (end to end 5.80269 ms, enqueue 5.76847 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72363 ms - Host latency: 5.79215 ms (end to end 5.80426 ms, enqueue 5.77028 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72657 ms - Host latency: 5.79542 ms (end to end 5.80919 ms, enqueue 5.77543 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72192 ms - Host latency: 5.791 ms (end to end 5.802 ms, enqueue 5.76848 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72 ms - Host latency: 5.7877 ms (end to end 5.80037 ms, enqueue 5.76655 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71213 ms - Host latency: 5.78088 ms (end to end 5.79211 ms, enqueue 5.75881 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70725 ms - Host latency: 5.7731 ms (end to end 5.78572 ms, enqueue 5.75652 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.70715 ms - Host latency: 5.77227 ms (end to end 5.78335 ms, enqueue 5.75503 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71003 ms - Host latency: 5.77754 ms (end to end 5.78896 ms, enqueue 5.7574 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71731 ms - Host latency: 5.78464 ms (end to end 5.79666 ms, enqueue 5.76436 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.7259 ms - Host latency: 5.79382 ms (end to end 5.80708 ms, enqueue 5.77322 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72815 ms - Host latency: 5.79834 ms (end to end 5.8124 ms, enqueue 5.77686 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71409 ms - Host latency: 5.78123 ms (end to end 5.7929 ms, enqueue 5.76191 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71067 ms - Host latency: 5.77686 ms (end to end 5.78911 ms, enqueue 5.75942 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.71841 ms - Host latency: 5.78455 ms (end to end 5.796 ms, enqueue 5.76594 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72417 ms - Host latency: 5.79277 ms (end to end 5.8054 ms, enqueue 5.77156 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72852 ms - Host latency: 5.79702 ms (end to end 5.81052 ms, enqueue 5.7761 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.73745 ms - Host latency: 5.8064 ms (end to end 5.82002 ms, enqueue 5.78362 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72898 ms - Host latency: 5.799 ms (end to end 5.8136 ms, enqueue 5.77788 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72556 ms - Host latency: 5.79607 ms (end to end 5.81006 ms, enqueue 5.77341 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72942 ms - Host latency: 5.79727 ms (end to end 5.81011 ms, enqueue 5.77432 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.73086 ms - Host latency: 5.79978 ms (end to end 5.81301 ms, enqueue 5.77793 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.72944 ms - Host latency: 5.79751 ms (end to end 5.80999 ms, enqueue 5.77515 ms)\n",
      "[04/18/2022-21:49:14] [I] Average on 10 runs - GPU latency: 5.73103 ms - Host latency: 5.79949 ms (end to end 5.81223 ms, enqueue 5.7782 ms)\n",
      "[04/18/2022-21:49:14] [I] \n",
      "[04/18/2022-21:49:14] [I] === Performance summary ===\n",
      "[04/18/2022-21:49:14] [I] Throughput: 171.664 qps\n",
      "[04/18/2022-21:49:14] [I] Latency: min = 5.75885 ms, max = 5.86975 ms, mean = 5.78582 ms, median = 5.78552 ms, percentile(99%) = 5.83044 ms\n",
      "[04/18/2022-21:49:14] [I] End-to-End Host Latency: min = 5.77002 ms, max = 5.88489 ms, mean = 5.79853 ms, median = 5.79822 ms, percentile(99%) = 5.84692 ms\n",
      "[04/18/2022-21:49:14] [I] Enqueue Time: min = 5.74219 ms, max = 5.83008 ms, mean = 5.76574 ms, median = 5.76526 ms, percentile(99%) = 5.79858 ms\n",
      "[04/18/2022-21:49:14] [I] H2D Latency: min = 0.0544586 ms, max = 0.0805664 ms, mean = 0.0576975 ms, median = 0.0574341 ms, percentile(99%) = 0.0673828 ms\n",
      "[04/18/2022-21:49:14] [I] GPU Compute Time: min = 5.69501 ms, max = 5.79456 ms, mean = 5.71835 ms, median = 5.71826 ms, percentile(99%) = 5.76001 ms\n",
      "[04/18/2022-21:49:14] [I] D2H Latency: min = 0.00695801 ms, max = 0.0290527 ms, mean = 0.00977761 ms, median = 0.00952148 ms, percentile(99%) = 0.0219727 ms\n",
      "[04/18/2022-21:49:14] [I] Total Host Walltime: 3.0117 s\n",
      "[04/18/2022-21:49:14] [I] Total GPU Compute Time: 2.95639 s\n",
      "[04/18/2022-21:49:14] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[04/18/2022-21:49:14] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[04/18/2022-21:49:14] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[04/18/2022-21:49:14] [I] \n",
      "[04/18/2022-21:49:14] [I] \n",
      "[04/18/2022-21:49:14] [I] === Profile (551 iterations ) ===\n",
      "[04/18/2022-21:49:14] [I]                                                                        Layer   Time (ms)   Avg. Time (ms)   Time %\n",
      "[04/18/2022-21:49:14] [I]                  Reformatting CopyNode for Input Tensor 0 to Conv_0 + Relu_1        6.18           0.0112      0.2\n",
      "[04/18/2022-21:49:14] [I]                                                              Conv_0 + Relu_1       40.12           0.0728      1.3\n",
      "[04/18/2022-21:49:14] [I]                                                                    MaxPool_2        4.80           0.0087      0.2\n",
      "[04/18/2022-21:49:14] [I]                                                              Conv_3 + Relu_4        8.69           0.0158      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                              Conv_5 + Relu_6       32.47           0.0589      1.0\n",
      "[04/18/2022-21:49:14] [I]                                                                       Conv_7       17.02           0.0309      0.5\n",
      "[04/18/2022-21:49:14] [I]                                                     Conv_8 + Add_9 + Relu_10        7.71           0.0140      0.2\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_11 + Relu_12       18.06           0.0328      0.6\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_13 + Relu_14       24.77           0.0450      0.8\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_15 + Add_16 + Relu_17       18.84           0.0342      0.6\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_18 + Relu_19       10.77           0.0195      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_20 + Relu_21       24.49           0.0445      0.8\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_22 + Add_23 + Relu_24        9.30           0.0169      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_25 + Relu_26       20.70           0.0376      0.7\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_27 + Relu_28       42.73           0.0776      1.4\n",
      "[04/18/2022-21:49:14] [I]                                                                      Conv_29       12.35           0.0224      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_30 + Add_31 + Relu_32       11.14           0.0202      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_33 + Relu_34       15.44           0.0280      0.5\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_35 + Relu_36       36.17           0.0657      1.2\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_37 + Add_38 + Relu_39       13.80           0.0250      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_40 + Relu_41       10.67           0.0194      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_42 + Relu_43       36.21           0.0657      1.2\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_44 + Add_45 + Relu_46        8.87           0.0161      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_47 + Relu_48       10.67           0.0194      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_49 + Relu_50       35.83           0.0650      1.1\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_51 + Add_52 + Relu_53        8.55           0.0155      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_54 + Relu_55       22.74           0.0413      0.7\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_56 + Relu_57       66.93           0.1215      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                                      Conv_58       16.05           0.0291      0.5\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_59 + Add_60 + Relu_61       12.38           0.0225      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_62 + Relu_63       14.58           0.0265      0.5\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_64 + Relu_65       69.18           0.1256      2.2\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_66 + Add_67 + Relu_68       15.10           0.0274      0.5\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_69 + Relu_70       10.75           0.0195      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_71 + Relu_72       63.95           0.1161      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_73 + Add_74 + Relu_75       12.03           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_76 + Relu_77       10.61           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_78 + Relu_79       63.83           0.1158      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_80 + Add_81 + Relu_82       12.02           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_83 + Relu_84       10.63           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_85 + Relu_86       64.49           0.1170      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_87 + Add_88 + Relu_89       12.02           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_90 + Relu_91       10.62           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_92 + Relu_93       64.69           0.1174      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                   Conv_94 + Add_95 + Relu_96       12.12           0.0220      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                            Conv_97 + Relu_98       10.67           0.0194      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                           Conv_99 + Relu_100       64.80           0.1176      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_101 + Add_102 + Relu_103       12.04           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_104 + Relu_105       10.61           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_106 + Relu_107       64.92           0.1178      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_108 + Add_109 + Relu_110       12.11           0.0220      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_111 + Relu_112       10.61           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_113 + Relu_114       64.58           0.1172      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_115 + Add_116 + Relu_117       11.93           0.0217      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_118 + Relu_119       10.60           0.0192      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_120 + Relu_121       64.48           0.1170      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_122 + Add_123 + Relu_124       12.10           0.0220      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_125 + Relu_126       10.71           0.0194      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_127 + Relu_128       64.18           0.1165      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_129 + Add_130 + Relu_131       12.02           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_132 + Relu_133       10.62           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_134 + Relu_135       63.90           0.1160      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_136 + Add_137 + Relu_138       12.11           0.0220      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_139 + Relu_140       10.63           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_141 + Relu_142       64.07           0.1163      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_143 + Add_144 + Relu_145       12.09           0.0219      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_146 + Relu_147       10.66           0.0194      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_148 + Relu_149       64.71           0.1174      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_150 + Add_151 + Relu_152       12.10           0.0220      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_153 + Relu_154       10.58           0.0192      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_155 + Relu_156       64.19           0.1165      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_157 + Add_158 + Relu_159       12.04           0.0219      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_160 + Relu_161       10.62           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_162 + Relu_163       64.55           0.1172      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_164 + Add_165 + Relu_166       12.15           0.0220      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_167 + Relu_168       10.63           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_169 + Relu_170       64.82           0.1176      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_171 + Add_172 + Relu_173       12.01           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_174 + Relu_175       10.65           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_176 + Relu_177       65.02           0.1180      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_178 + Add_179 + Relu_180       12.15           0.0221      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_181 + Relu_182       10.73           0.0195      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_183 + Relu_184       63.85           0.1159      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_185 + Add_186 + Relu_187       12.01           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_188 + Relu_189       10.59           0.0192      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_190 + Relu_191       64.19           0.1165      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_192 + Add_193 + Relu_194       12.03           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_195 + Relu_196       10.60           0.0192      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_197 + Relu_198       63.85           0.1159      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_199 + Add_200 + Relu_201       12.03           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_202 + Relu_203       10.64           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_204 + Relu_205       64.70           0.1174      2.1\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_206 + Add_207 + Relu_208       12.10           0.0220      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_209 + Relu_210       10.65           0.0193      0.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_211 + Relu_212       64.25           0.1166      2.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_213 + Add_214 + Relu_215       12.02           0.0218      0.4\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_216 + Relu_217       21.95           0.0398      0.7\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_218 + Relu_219      135.24           0.2455      4.3\n",
      "[04/18/2022-21:49:14] [I]                                                                     Conv_220       20.71           0.0376      0.7\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_221 + Add_222 + Relu_223       23.43           0.0425      0.7\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_224 + Relu_225       42.01           0.0762      1.3\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_226 + Relu_227      132.59           0.2406      4.2\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_228 + Add_229 + Relu_230       22.29           0.0404      0.7\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_231 + Relu_232       34.77           0.0631      1.1\n",
      "[04/18/2022-21:49:14] [I]                                                          Conv_233 + Relu_234      126.63           0.2298      4.0\n",
      "[04/18/2022-21:49:14] [I]                                                Conv_235 + Add_236 + Relu_237       19.64           0.0357      0.6\n",
      "[04/18/2022-21:49:14] [I]                                                        GlobalAveragePool_238        5.55           0.0101      0.2\n",
      "[04/18/2022-21:49:14] [I]                         Reformatting CopyNode for Input Tensor 0 to Gemm_240        1.91           0.0035      0.1\n",
      "[04/18/2022-21:49:14] [I]                                                                     Gemm_240       12.32           0.0224      0.4\n",
      "[04/18/2022-21:49:14] [I]                                               (Unnamed Layer* 255) [Shuffle]        1.91           0.0035      0.1\n",
      "[04/18/2022-21:49:14] [I]  Reformatting CopyNode for Output Tensor 0 to (Unnamed Layer* 255) [Shuffle]        3.40           0.0062      0.1\n",
      "[04/18/2022-21:49:14] [I]                                                                        Total     3136.32           5.6921    100.0\n",
      "[04/18/2022-21:49:14] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8203] # trtexec --loadEngine=model.plan --dumpProfile\n"
     ]
    }
   ],
   "source": [
    "!trtexec --loadEngine=model.plan --dumpProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435e919",
   "metadata": {},
   "source": [
    "## What if I got error messages during this step?\n",
    "\n",
    "1. Try [Onnx-Simplifier](https://github.com/daquexian/onnx-simplifier)\n",
    "```python3 -m onnxsim model.onnx simplified_model.onnx```\n",
    "\n",
    "2. [Custom Plugin?](https://github.com/NVIDIA/TensorRT), [Onnx-GraphSurgeon?](https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon)\n",
    "\n",
    "3. Use Framework integration version (TF-TRT, Torch-TRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6c369",
   "metadata": {},
   "source": [
    "## Supported Matrix\n",
    "\n",
    "https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html#supported-ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550a13b",
   "metadata": {},
   "source": [
    "## Build TensorRT (Torch-TRT)\n",
    "\n",
    "- Torch-TRT\n",
    "https://nvidia.github.io/Torch-TensorRT/tutorials/getting_started_with_python_api.html\n",
    "\n",
    "- TF-TRT\n",
    "https://github.com/tensorflow/tensorrt/tree/master/tftrt/examples/image_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f3524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n"
     ]
    }
   ],
   "source": [
    "#Optional\n",
    "import torch\n",
    "import torch_tensorrt as torchtrt\n",
    "\n",
    "model = models.wide_resnet101_2(pretrained=True).eval().cuda()\n",
    "#Or you can load torchscript file directly likes\n",
    "#model = torch.jit.load('ts_model_path')\n",
    "\n",
    "trt_module = torchtrt.compile(model, inputs=[torchtrt.Input(\n",
    "                                min_shape=[1, 3, 224, 224],\n",
    "                                opt_shape=[16, 3, 224, 224],\n",
    "                                max_shape=[32, 3, 224, 224], )], enabled_precisions={torch.half})\n",
    "\n",
    "trt_module.save('test.ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a173c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf models\n",
    "!mkdir -p models/torch_model\n",
    "!mkdir -p models/torch_model/1\n",
    "!mkdir -p models/onnx_model\n",
    "!mkdir -p models/onnx_model/1\n",
    "!mkdir -p models/trt_model\n",
    "!mkdir -p models/trt_model/1\n",
    "\n",
    "!mv model.pt models/torch_model/1\n",
    "!mv model.onnx models/onnx_model/1\n",
    "!mv model.plan models/trt_model/1\n",
    "\n",
    "!cp src/onnx_config.pbtxt models/onnx_model/config.pbtxt\n",
    "!cp src/torch_config.pbtxt models/torch_model/config.pbtxt\n",
    "!cp src/trt_config.pbtxt models/trt_model/config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1084840",
   "metadata": {},
   "source": [
    "## Let's go to the Chapter 2 (Triton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a843c21",
   "metadata": {},
   "source": [
    "### Additional Topic: PTQ & QAT\n",
    "\n",
    "Low-level Interface\n",
    "https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/infer/Int8/EntropyCalibrator2.html\n",
    "\n",
    "Polygraphy\n",
    "https://github.com/NVIDIA/TensorRT/tree/master/tools/Polygraphy/examples/cli/convert/01_int8_calibration_in_tensorrt\n",
    "\n",
    "Great example(Efficientdet)\n",
    "https://github.com/NVIDIA/TensorRT/tree/main/samples/python/efficientdet\n",
    "\n",
    "Torch-TRT example\n",
    "https://github.com/NVIDIA/Torch-TensorRT/blob/master/tests/py/test_ptq_dataloader_calibrator.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
